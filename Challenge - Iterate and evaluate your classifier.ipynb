{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab and process the raw data.\n",
    "imdb = pd.read_csv('imdb_labelled.txt', delimiter= '\\t', header=None)\n",
    "imdb.columns = ['review', 'positive']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords1 = ['best', 'adorable', 'loved', 'decent', 'terrific', 'liked', 'brilliant', 'rocked', 'great', 'fun', 'funny', '10']\n",
    "\n",
    "\n",
    "keywords2 = ['best', 'adorable', 'loved', 'decent', 'terrific',\n",
    "            'liked', 'brilliant', 'rocked', 'great', 'fun',\n",
    "            'funny', '10', 'happy', 'worth', 'good', 'classic',\n",
    "           'stars', 'treat', 'entertaining', 'smart', 'recommend', \n",
    "           'hot', 'wonderful', 'adventure', 'humor', 'humour', 'popular',\n",
    "           'enjoyed', 'like', 'love', 'excellent', 'uplifting', 'amazed',\n",
    "           'amazing', 'spectacular', 'mesmorizing','mesmerizing', \n",
    "            'excellent', 'balance', 'decent', 'rocked', 'sweet', 'pleased', \n",
    "           'awesome', 'powerful', 'solid', 'hilarious', 'identify', 'likes',\n",
    "           'impressed', 'wonderful', 'appreciate', 'enjoy', 'enjoyed', 'recommended',\n",
    "           'sincere', 'genuine', 'chemistry', 'natural', 'incredible', 'lovely', \n",
    "           'recommend', 'clever', 'hip', 'amazing']\n",
    "keywords3 = ['best', 'adorable', 'loved', 'decent', 'terrific',\n",
    "            'liked', 'brilliant', 'rocked', 'great', 'fun',\n",
    "             '10', 'happy','classic',\n",
    "            'recommend', \n",
    "           'hot', 'wonderful', 'adventure', 'humor', 'humour', 'popular',\n",
    "           'enjoyed', 'like', 'love', 'excellent', 'uplifting', 'amazed',\n",
    "           'amazing', 'spectacular', 'mesmorizing','mesmerizing', \n",
    "            'excellent', 'decent', 'rocked', 'pleased', \n",
    "           'awesome', 'powerful', 'solid', 'hilarious', 'identify', 'likes',\n",
    "           'impressed', 'wonderful', 'appreciate', 'enjoy', 'enjoyed', 'recommended',\n",
    "           'sincere', 'genuine', 'incredible', 'lovely', \n",
    "           'recommend', 'clever', 'amazing']\n",
    "keywords4 = ['loved', 'great', 'wonderful', 'enjoyed', 'amazing', \n",
    "             'genuine', '10','classic']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = keywords2\n",
    "for key in keywords:\n",
    "    imdb[str(key)] = imdb.review.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['positive'] = (imdb['positive'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = imdb[keywords]\n",
    "target = imdb['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total of 748 points : 245\n"
     ]
    }
   ],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "y_pred = bnb.fit(data, target).predict(data)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total of {} points : {}\".format(\n",
    "     data.shape[0],\n",
    "     (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.58\n",
      "Testing on Sample: 0.6724598930481284\n"
     ]
    }
   ],
   "source": [
    "# Test your model with different holdout groups.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59210526, 0.67105263, 0.70666667, 0.6       , 0.69333333,\n",
       "       0.6       , 0.72972973, 0.59459459, 0.62162162, 0.60810811])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(598, 65) (598,)\n",
      "(150, 65) (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1 = data\n",
    "y1 = target\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2)\n",
    "print(X1_train.shape, y1_train.shape)\n",
    "print(X1_test.shape, y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6733333333333333\n",
      "Score: 0.6133333333333333\n",
      "Score: 0.6333333333333333\n",
      "Score: 0.6711409395973155\n",
      "Score: 0.5973154362416108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#Cross validation model\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "kf = KFold(n_splits = 5, shuffle=True, random_state = 40)\n",
    "bnb = BernoulliNB() \n",
    "for train_index, test_index in kf.split(X1):\n",
    "    X1_train, X1_test = X1.iloc[train_index], X1.iloc[test_index]\n",
    "    y1_train, y1_test = y1.iloc[train_index], y1.iloc[test_index]\n",
    "    bnb = bnb.fit(X1_train, y1_train)\n",
    "    print(\"Score:\", bnb.score(X1_test, y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keywords1: Number of mislabeled points out of a total of 748 points : 324\n",
    "\n",
    "Keywords2: Number of mislabeled points out of a total of 748 points : 245\n",
    "\n",
    "Keywords3: Number of mislabeled points out of a total of 748 points : 265\n",
    "\n",
    "Keywords3: Number of mislabeled points out of a total of 748 points : 335\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
